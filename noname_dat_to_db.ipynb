{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT data base integration with matching (no-name DAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "import sqlite3\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympic Games 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataFolder = \"/Users/falkowork/Downloads/WCH Tokyo TRA Herren/Day 1 TRA Men/\"\n",
    "dataFolder = \"/Users/falkowork/Downloads/Olympia 2021 Tokyo/SOLG_Tokyo_2020_GT_Men_EuroTrampMachines_Logs/\"\n",
    "db_name = \"2020_olympic_games_men\"\n",
    "sortedList = sorted(os.listdir(dataFolder))\n",
    "header = ('Start Number', \"Gender\", \"Country\", \"Phase\", \"Routine\", \"Name\", \"Hash\")\n",
    "df_main = pd.DataFrame(columns=header)\n",
    "engine = create_engine('mysql+pymysql://falkoin:Tim!nA|$tr0wd$10wSp3rSEs@localhost/trampoline', pool_recycle=3600)\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(\"SELECT * from ranklists\", conn)\n",
    "df_wctokyo = df[(df['Event']=='Olympic Games') & (df['Location']=='Tokyo') & (df['Gender']=='Men')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Match: 0, No Match: 24, All: 68, Matched: 38\n"
     ]
    }
   ],
   "source": [
    "routine = '0'\n",
    "phase = '0'\n",
    "t_list = []\n",
    "mmc = 0\n",
    "nmc = 0\n",
    "gmc = 0\n",
    "allc = 0\n",
    "names = []\n",
    "h_list = []\n",
    "t_s = []\n",
    "start_number = 0\n",
    "for dataset in sortedList:\n",
    "    if not \".DS_Store\" in dataset:\n",
    "        allc += 1\n",
    "        # idx += 1\n",
    "        # print(idx)\n",
    "        datContent = [i.strip().split() for i in open(dataFolder + dataset).readlines()]\n",
    "        trampoline_data = datContent[4:14]\n",
    "        df_trampoline = pd.DataFrame(trampoline_data)\n",
    "        if len(df_trampoline.columns) > 2:\n",
    "            df_trampoline.drop([0, 1, 3], axis=1,inplace=True)\n",
    "            header = (\"T\", \"H\", \"x\", \"y\")\n",
    "            df_trampoline.columns = header\n",
    "            sum_h = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['H'].to_list()])\n",
    "            sum_t = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['T'].to_list()])\n",
    "            \n",
    "            \n",
    "            test = df_wctokyo[(round(df_wctokyo['H']*1000).astype(int)==sum_h) & (round(df_wctokyo['T']*1000).astype(int)==sum_t)]\n",
    "            # if dataset == '20210731_135110.dat':\n",
    "            # print('H: {0}, T: {1}'.format(sum_h, sum_t))\n",
    "            #     print(df_trampoline)\n",
    "            if len(test) > 1:\n",
    "                mmc += 1\n",
    "                # print(dataset)\n",
    "                # print(test['Name'])\n",
    "            elif len(test) == 0:\n",
    "                nmc += 1\n",
    "                # print(dataset)\n",
    "                # print(\"No Match\")\n",
    "                # print(sum_t)\n",
    "            elif len(test) == 1:\n",
    "                # if gmc == 0:\n",
    "                #     print('H: {0}, T: {1}'.format(sum_h, sum_t))\n",
    "                #     print(test)\n",
    "                t_list.append(sum_t)\n",
    "                h_list.append(sum_h)\n",
    "                names.append(test[\"Name\"].iloc[0])\n",
    "\n",
    "                # creates hash from filename\n",
    "                hash_val = hashlib.md5(dataset.encode('UTF-8')).hexdigest()\n",
    "                with engine.connect() as conn:\n",
    "                    df_trampoline.to_sql(name=hash_val, con=conn, if_exists='replace')\n",
    "\n",
    "                # creates temporary df\n",
    "                name = test[\"Name\"].iloc[0].split()\n",
    "                name = name[0].capitalize() + \" \" + name[1].capitalize()\n",
    "                check_df = df_main[(df_main['Name']==name)]\n",
    "                if len(check_df) == 0:\n",
    "                    routine = '1st'\n",
    "                    phase = 'Qualification'\n",
    "                elif len(check_df) == 1:\n",
    "                    routine = '2nd'\n",
    "                    phase = 'Qualification'\n",
    "                elif len(check_df) == 2:\n",
    "                    routine = '1st'\n",
    "                    phase = 'Final'\n",
    "                d = {\n",
    "                    'Start Number': start_number, \n",
    "                    \"Gender\": test[\"Gender\"].iloc[0], \n",
    "                    \"Country\": test[\"Country\"].iloc[0], \n",
    "                    \"Phase\": phase, \n",
    "                    \"Routine\": routine, \n",
    "                    \"Name\": name, \n",
    "                    \"Hash\": hash_val\n",
    "                }\n",
    "                df_temp = pd.DataFrame(d, index=[gmc])\n",
    "                df_main = pd.concat([df_main, df_temp])\n",
    "                gmc += 1\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_main.to_sql(name=db_name, con=conn, if_exists='replace')\n",
    "print('Multi Match: {0}, No Match: {1}, All: {2}, Matched: {3}'.format(mmc, nmc, allc, gmc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataFolder = \"/Users/falkowork/Downloads/WCH Tokyo TRA Herren/Day 1 TRA Men/\"\n",
    "dataFolder = \"/Users/falkowork/Downloads/Olympia 2021 Tokyo/SOLG_Tokyo_2020_GT_Women_EuroTrampMachines_Logs/\"\n",
    "db_name = \"2020_olympic_games_women\"\n",
    "sortedList = sorted(os.listdir(dataFolder))\n",
    "header = ('Start Number', \"Gender\", \"Country\", \"Phase\", \"Routine\", \"Name\", \"Hash\")\n",
    "df_main = pd.DataFrame(columns=header)\n",
    "# df = pd.read_sql(\"SELECT * from ranklists\", connection)\n",
    "df_wctokyo = df[(df['Event']=='Olympic Games') & (df['Location']=='Tokyo') & (df['Gender']=='Women')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: 9400, T: 16205\n",
      "Multi Match: 0, No Match: 22, All: 74, Matched: 39\n"
     ]
    }
   ],
   "source": [
    "routine = '0'\n",
    "phase = '0'\n",
    "t_list = []\n",
    "mmc = 0\n",
    "nmc = 0\n",
    "gmc = 0\n",
    "allc = 0\n",
    "names = []\n",
    "h_list = []\n",
    "t_s = []\n",
    "start_number = 0\n",
    "for dataset in sortedList:\n",
    "    if not \".DS_Store\" in dataset:\n",
    "        allc += 1\n",
    "        # idx += 1\n",
    "        # print(idx)\n",
    "        datContent = [i.strip().split() for i in open(dataFolder + dataset).readlines()]\n",
    "        trampoline_data = datContent[4:14]\n",
    "        df_trampoline = pd.DataFrame(trampoline_data)\n",
    "        if len(df_trampoline.columns) > 2:\n",
    "            df_trampoline.drop([0, 1, 3], axis=1,inplace=True)\n",
    "            header = (\"T\", \"H\", \"x\", \"y\")\n",
    "            df_trampoline.columns = header\n",
    "            sum_h = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['H'].to_list()])\n",
    "            sum_t = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['T'].to_list()])\n",
    "            \n",
    "            \n",
    "            test = df_wctokyo[(round(df_wctokyo['H']*1000).astype(int)==sum_h) & (round(df_wctokyo['T']*1000).astype(int)==sum_t)]\n",
    "            if dataset == '20210730_135416.dat':\n",
    "                print('H: {0}, T: {1}'.format(sum_h, sum_t))\n",
    "            #     print(df_trampoline)\n",
    "            if len(test) > 1:\n",
    "                mmc += 1\n",
    "                # print(dataset)\n",
    "                # print(test['Name'])\n",
    "            elif len(test) == 0:\n",
    "                nmc += 1\n",
    "                # print(dataset)\n",
    "                # print(\"No Match\")\n",
    "                # print(sum_t)\n",
    "            elif len(test) == 1:\n",
    "                # if gmc == 0:\n",
    "                #     print('H: {0}, T: {1}'.format(sum_h, sum_t))\n",
    "                #     print(test)\n",
    "                t_list.append(sum_t)\n",
    "                h_list.append(sum_h)\n",
    "                names.append(test[\"Name\"].iloc[0])\n",
    "\n",
    "                # creates hash from filename\n",
    "                hash_val = hashlib.md5(dataset.encode('UTF-8')).hexdigest()\n",
    "                with engine.connect() as conn:\n",
    "                    df_trampoline.to_sql(name=hash_val, con=conn, if_exists='replace')\n",
    "\n",
    "                # creates temporary df\n",
    "                name = test[\"Name\"].iloc[0].split()\n",
    "                name = name[0].capitalize() + \" \" + name[1].capitalize()\n",
    "                check_df = df_main[(df_main['Name']==name)]\n",
    "                if len(check_df) == 0:\n",
    "                    routine = '1st'\n",
    "                    phase = 'Qualification'\n",
    "                elif len(check_df) == 1:\n",
    "                    routine = '2nd'\n",
    "                    phase = 'Qualification'\n",
    "                elif len(check_df) == 2:\n",
    "                    routine = '1st'\n",
    "                    phase = 'Final'\n",
    "                d = {\n",
    "                    'Start Number': start_number, \n",
    "                    \"Gender\": test[\"Gender\"].iloc[0], \n",
    "                    \"Country\": test[\"Country\"].iloc[0], \n",
    "                    \"Phase\": phase, \n",
    "                    \"Routine\": routine, \n",
    "                    \"Name\": name, \n",
    "                    \"Hash\": hash_val\n",
    "                }\n",
    "                df_temp = pd.DataFrame(d, index=[gmc])\n",
    "                df_main = pd.concat([df_main, df_temp])\n",
    "                gmc += 1\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_main.to_sql(name=db_name, con=conn)\n",
    "print('Multi Match: {0}, No Match: {1}, All: {2}, Matched: {3}'.format(mmc, nmc, allc, gmc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WCH TokyO 2019\n",
    "### Men\n",
    "### Qualification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = \"/Users/falkowork/Downloads/Data/WCH Tokyo TRA Herren/Day 1 TRA Men/\"\n",
    "# dataFolder = \"/Users/falkowork/Downloads/Olympia 2021 Tokyo/SOLG_Tokyo_2020_GT_Men_EuroTrampMachines_Logs/\"\n",
    "db_name = \"2019_world_championships_men\"\n",
    "sortedList = sorted(os.listdir(dataFolder))\n",
    "header = ('Start Number', \"Gender\", \"Country\", \"Phase\", \"Routine\", \"Name\", \"Hash\")\n",
    "df_main = pd.DataFrame(columns=header)\n",
    "df_wctokyo = df[(df['Event']=='World Championships') & (df['Location']=='Tokyo') & (df['Gender']=='Men')]\n",
    "df_overall = pd.DataFrame(columns=header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripname(name):\n",
    "    # print(name)\n",
    "    name = name.strip().split()\n",
    "    return name[0].capitalize() + \" \" + name[1].capitalize()\n",
    "    # print(name)\n",
    "\n",
    "startlist = pd.read_csv(\"WCH_Tokyo_Startlist_Men.csv\", header=None)\n",
    "header = ('Start', 'Start Number', 'Name', 'Country')\n",
    "startlist.columns = header\n",
    "# startlist[\"Name\"] = startlist.apply(lambda x: x[\"Name\"].strip(), axis=1)\n",
    "startlist[\"Name\"] = startlist.apply(lambda x: stripname(x[\"Name\"]), axis=1)\n",
    "group_list = []\n",
    "group = 0\n",
    "last_idx = 0\n",
    "routine = '1st'\n",
    "routine_list = []\n",
    "groups = [1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9]\n",
    "for entry in startlist[\"Start\"]:\n",
    "    \n",
    "    # print(\"Last Index {0} - Entry {1}\".format(last_idx, entry))\n",
    "    if last_idx >= entry:\n",
    "        last_idx = 0\n",
    "        group += 1\n",
    "        if routine == '1st':\n",
    "            routine = '2nd'\n",
    "        elif routine == '2nd':\n",
    "            routine = '1st'\n",
    "    else:\n",
    "        last_idx = entry\n",
    "\n",
    "    group_list.append(groups[group])\n",
    "    routine_list.append(routine)\n",
    "\n",
    "startlist[\"Group\"] = group_list\n",
    "startlist[\"Routine\"] = routine_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat = pd.DataFrame(columns=('Filename', 'T', 'H'))\n",
    "filenames = []\n",
    "t_list = []\n",
    "h_list = []\n",
    "hash_table = []\n",
    "for dataset in sortedList:\n",
    "        if not \".DS_Store\" in dataset:\n",
    "            datContent = [i.strip().split() for i in open(dataFolder + dataset).readlines()]\n",
    "            trampoline_data = datContent[4:14]\n",
    "            df_trampoline = pd.DataFrame(trampoline_data)\n",
    "            if len(df_trampoline.columns) > 2:\n",
    "                df_trampoline.drop([0, 1, 3], axis=1,inplace=True)\n",
    "                header = (\"T\", \"H\", \"x\", \"y\")\n",
    "                df_trampoline.columns = header\n",
    "                sum_h = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['H'].to_list()])\n",
    "                sum_t = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['T'].to_list()])\n",
    "                t_list.append(sum_t)\n",
    "                h_list.append(sum_h)\n",
    "                hash_val = hashlib.md5(dataset.encode('UTF-8')).hexdigest()\n",
    "                hash_table.append(hash_val)\n",
    "                with engine.connect() as conn:\n",
    "                    df_trampoline.to_sql(name=hash_val, con=conn, if_exists='replace')\n",
    "                \n",
    "            else:\n",
    "                t_list.append(0)\n",
    "                h_list.append(0)\n",
    "                hash_table.append('')\n",
    "            filenames.append(dataset)\n",
    "df_dat['Filename'] = filenames\n",
    "df_dat['H'] = h_list\n",
    "df_dat['T'] = t_list\n",
    "df_dat['Hash'] = hash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j8/4ddprkx52x3f2x85fg7w74k00000gn/T/ipykernel_82037/4015572544.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_wctokyo[\"Name\"] = df_wctokyo.apply(lambda x: stripname(x[\"Name\"]), axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_datsave = df_dat.copy()\n",
    "h_rating = []\n",
    "t_rating = []\n",
    "dataset_list = []\n",
    "matched = 0\n",
    "hash_list = []\n",
    "df_wctokyo[\"Name\"] = df_wctokyo.apply(lambda x: stripname(x[\"Name\"]), axis=1)\n",
    "for idx, entry in startlist.iterrows():\n",
    "    \n",
    "    entry_with_rating = df_wctokyo[(df_wctokyo['Name']==entry['Name']) & (df_wctokyo['Routine']==entry['Routine'])]\n",
    "    \n",
    "    if len(entry_with_rating) > 0:\n",
    "        h_rating.append(entry_with_rating['H'].iloc[0])\n",
    "        t_rating.append(entry_with_rating['T'].iloc[0])\n",
    "\n",
    "        h_cents = int(round(entry_with_rating['H'].iloc[0]*1000))\n",
    "        t_cents = int(round(entry_with_rating['T'].iloc[0]*1000))\n",
    "\n",
    "        df_select = df_datsave[((df_datsave['H']==h_cents) & (df_datsave['T']==t_cents))]\n",
    "        \n",
    "        if len(df_select) > 0:\n",
    "            dataset_list.append(df_select['Filename'].iloc[0])\n",
    "            hash_list.append(df_select['Hash'].iloc[0])\n",
    "            # df_datsave = df_datsave.drop([df_select.index[0]])\n",
    "            matched += 1\n",
    "        elif len(df_select) == 0:\n",
    "            dataset_list.append('')\n",
    "            hash_list.append('')\n",
    "    elif len(entry_with_rating) == 0:\n",
    "        h_rating.append(0)\n",
    "        t_rating.append(0)\n",
    "        dataset_list.append('')\n",
    "        hash_list.append('')\n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "startlist['H'] = h_rating\n",
    "startlist['T'] = t_rating\n",
    "startlist['Filename'] = dataset_list\n",
    "startlist[\"Phase\"] = \"Qualification\"\n",
    "startlist['Hash'] = hash_list\n",
    "startlist = startlist.drop([\"Start\", \"Filename\", \"Group\", 'T', 'H'], axis=1)\n",
    "# startlist.to_sql(name=db_name, con=connection)\n",
    "# connection.close()\n",
    "# print(matched)\n",
    "df_overall = pd.concat([df_overall, startlist])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = \"/Users/falkowork/Downloads/Data/WCH Tokyo TRA Herren/Day 3 TRA Men/\"\n",
    "# dataFolder = \"/Users/falkowork/Downloads/Olympia 2021 Tokyo/SOLG_Tokyo_2020_GT_Men_EuroTrampMachines_Logs/\"\n",
    "# db_name = \"2019_world_championships_men\"\n",
    "sortedList = sorted(os.listdir(dataFolder))\n",
    "header = ('Start Number', \"Gender\", \"Country\", \"Phase\", \"Routine\", \"Name\", \"Hash\")\n",
    "df_main = pd.DataFrame(columns=header)\n",
    "# connection = sqlite3.connect(\"trampoline.db\")\n",
    "# cursor = connection.cursor()\n",
    "# df = pd.read_sql(\"SELECT * from ranklists\", connection)\n",
    "df_wctokyo = df[(df['Event']=='World Championships') & (df['Location']=='Tokyo') & (df['Gender']=='Men') & (df['Phase']=='Semi')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: 8900, T: 16550\n",
      "H: 1000, T: 1840\n",
      "H: 8900, T: 15800\n",
      "H: 9400, T: 17290\n",
      "H: 9000, T: 17225\n",
      "H: 9100, T: 15920\n",
      "H: 9400, T: 16280\n",
      "H: 9200, T: 17130\n",
      "H: 9100, T: 16745\n",
      "H: 9400, T: 16475\n",
      "H: 9000, T: 17155\n",
      "H: 9400, T: 17300\n",
      "H: 1000, T: 1870\n",
      "H: 9400, T: 17080\n",
      "H: 9500, T: 16795\n",
      "H: 9100, T: 17415\n",
      "H: 9200, T: 16755\n",
      "H: 9300, T: 16870\n",
      "H: 9200, T: 16735\n",
      "H: 9400, T: 16845\n",
      "H: 9100, T: 17700\n",
      "H: 9800, T: 17090\n",
      "H: 9700, T: 17760\n",
      "H: 8700, T: 16755\n",
      "Multi Match: 0, No Match: 0, All: 32, Matched: 24\n"
     ]
    }
   ],
   "source": [
    "routine = '0'\n",
    "phase = '0'\n",
    "t_list = []\n",
    "mmc = 0\n",
    "nmc = 0\n",
    "gmc = 0\n",
    "allc = 0\n",
    "names = []\n",
    "h_list = []\n",
    "t_s = []\n",
    "start_number = 0\n",
    "for dataset in sortedList:\n",
    "    if not \".DS_Store\" in dataset:\n",
    "        allc += 1\n",
    "        # idx += 1\n",
    "        # print(idx)\n",
    "        datContent = [i.strip().split() for i in open(dataFolder + dataset).readlines()]\n",
    "        trampoline_data = datContent[4:14]\n",
    "        df_trampoline = pd.DataFrame(trampoline_data)\n",
    "        which_competition = datContent[0][-1]\n",
    "        if (len(df_trampoline.columns) > 2 and int(which_competition) < 3):\n",
    "            df_trampoline.drop([0, 1, 3], axis=1,inplace=True)\n",
    "            header = (\"T\", \"H\", \"x\", \"y\")\n",
    "            df_trampoline.columns = header\n",
    "            sum_h = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['H'].to_list()])\n",
    "            sum_t = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['T'].to_list()])\n",
    "            \n",
    "            \n",
    "            test = df_wctokyo[(round(df_wctokyo['H']*1000).astype(int)==sum_h) & (round(df_wctokyo['T']*1000).astype(int)==sum_t)]\n",
    "            # if dataset == '20210731_135110.dat':\n",
    "            print('H: {0}, T: {1}'.format(sum_h, sum_t))\n",
    "            #     print(df_trampoline)\n",
    "            if len(test) > 1:\n",
    "                mmc += 1\n",
    "                # print(dataset)\n",
    "                # print(test['Name'])\n",
    "            elif len(test) == 0:\n",
    "                nmc += 1\n",
    "                # print(dataset)\n",
    "                # print(\"No Match\")\n",
    "                # print(sum_t)\n",
    "            elif len(test) == 1:\n",
    "                # if gmc == 0:\n",
    "                #     print('H: {0}, T: {1}'.format(sum_h, sum_t))\n",
    "                #     print(test)\n",
    "                t_list.append(sum_t)\n",
    "                h_list.append(sum_h)\n",
    "                names.append(test[\"Name\"].iloc[0])\n",
    "\n",
    "                # creates hash from filename\n",
    "                hash_val = hashlib.md5(dataset.encode('UTF-8')).hexdigest()\n",
    "                with engine.connect() as conn:\n",
    "                    df_trampoline.to_sql(name=hash_val, con=conn, if_exists='replace')\n",
    "\n",
    "                # creates temporary df\n",
    "                name = test[\"Name\"].iloc[0].split()\n",
    "                name = name[0].capitalize() + \" \" + name[1].capitalize()\n",
    "                check_df = df_main[(df_main['Name']==name)]\n",
    "                if len(check_df) == 0:\n",
    "                    routine = '1st'\n",
    "                    phase = 'Qualification'\n",
    "                elif len(check_df) == 1:\n",
    "                    routine = '2nd'\n",
    "                    phase = 'Qualification'\n",
    "                elif len(check_df) == 2:\n",
    "                    routine = '1st'\n",
    "                    phase = 'Final'\n",
    "                d = {\n",
    "                    'Start Number': start_number, \n",
    "                    \"Gender\": test[\"Gender\"].iloc[0], \n",
    "                    \"Country\": test[\"Country\"].iloc[0], \n",
    "                    \"Phase\": phase, \n",
    "                    \"Routine\": routine, \n",
    "                    \"Name\": name, \n",
    "                    \"Hash\": hash_val\n",
    "                }\n",
    "                df_temp = pd.DataFrame(d, index=[gmc])\n",
    "                df_main = pd.concat([df_main, df_temp])\n",
    "                gmc += 1\n",
    "\n",
    "df_main[\"Phase\"] = 'Semi'\n",
    "# df_main.to_sql(name=db_name, con=connection)\n",
    "df_overall = pd.concat([df_overall, df_main])\n",
    "print('Multi Match: {0}, No Match: {1}, All: {2}, Matched: {3}'.format(mmc, nmc, allc, gmc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = \"/Users/falkowork/Downloads/Data/WCH Tokyo TRA Herren/Day 4 TRA Men/\"\n",
    "# dataFolder = \"/Users/falkowork/Downloads/Olympia 2021 Tokyo/SOLG_Tokyo_2020_GT_Men_EuroTrampMachines_Logs/\"\n",
    "# db_name = \"2019_world_championships_women\"\n",
    "sortedList = sorted(os.listdir(dataFolder))\n",
    "header = ('Start Number', \"Gender\", \"Country\", \"Phase\", \"Routine\", \"Name\", \"Hash\")\n",
    "df_main = pd.DataFrame(columns=header)\n",
    "# connection = sqlite3.connect(\"trampoline.db\")\n",
    "# cursor = connection.cursor()\n",
    "# df = pd.read_sql(\"SELECT * from ranklists\", connection)\n",
    "df_wctokyo = df[(df['Event']=='World Championships') & (df['Location']=='Tokyo') & (df['Gender']=='Men') & (df['Phase']=='Final')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: 9200, T: 17330\n",
      "H: 9300, T: 17185\n",
      "H: 6500, T: 12135\n",
      "H: 8900, T: 16750\n",
      "H: 9700, T: 17050\n",
      "H: 9500, T: 16565\n",
      "H: 9500, T: 17920\n",
      "H: 9600, T: 17905\n",
      "H: 2700, T: 5325\n",
      "H: 9900, T: 17795\n",
      "H: 9100, T: 16415\n",
      "H: 1600, T: 3465\n",
      "H: 9000, T: 17125\n",
      "Multi Match: 0, No Match: 5, All: 18, Matched: 8\n"
     ]
    }
   ],
   "source": [
    "routine = '0'\n",
    "phase = '0'\n",
    "t_list = []\n",
    "mmc = 0\n",
    "nmc = 0\n",
    "gmc = 0\n",
    "allc = 0\n",
    "names = []\n",
    "h_list = []\n",
    "t_s = []\n",
    "start_number = 0\n",
    "for dataset in sortedList:\n",
    "    if not \".DS_Store\" in dataset:\n",
    "        allc += 1\n",
    "        # idx += 1\n",
    "        # print(idx)\n",
    "        datContent = [i.strip().split() for i in open(dataFolder + dataset).readlines()]\n",
    "        trampoline_data = datContent[4:14]\n",
    "        df_trampoline = pd.DataFrame(trampoline_data)\n",
    "        which_competition = datContent[0][-1]\n",
    "        if (len(df_trampoline.columns) > 2 and int(which_competition) < 3):\n",
    "            df_trampoline.drop([0, 1, 3], axis=1,inplace=True)\n",
    "            header = (\"T\", \"H\", \"x\", \"y\")\n",
    "            df_trampoline.columns = header\n",
    "            sum_h = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['H'].to_list()])\n",
    "            sum_t = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['T'].to_list()])\n",
    "            \n",
    "            \n",
    "            test = df_wctokyo[(round(df_wctokyo['H']*1000).astype(int)==sum_h) & (round(df_wctokyo['T']*1000).astype(int)==sum_t)]\n",
    "            # if dataset == '20210731_135110.dat':\n",
    "            print('H: {0}, T: {1}'.format(sum_h, sum_t))\n",
    "            #     print(df_trampoline)\n",
    "            if len(test) > 1:\n",
    "                mmc += 1\n",
    "                # print(dataset)\n",
    "                # print(test['Name'])\n",
    "            elif len(test) == 0:\n",
    "                nmc += 1\n",
    "                # print(dataset)\n",
    "                # print(\"No Match\")\n",
    "                # print(sum_t)\n",
    "            elif len(test) == 1:\n",
    "                # if gmc == 0:\n",
    "                #     print('H: {0}, T: {1}'.format(sum_h, sum_t))\n",
    "                #     print(test)\n",
    "                t_list.append(sum_t)\n",
    "                h_list.append(sum_h)\n",
    "                names.append(test[\"Name\"].iloc[0])\n",
    "\n",
    "                # creates hash from filename\n",
    "                hash_val = hashlib.md5(dataset.encode('UTF-8')).hexdigest()\n",
    "                with engine.connect() as conn:\n",
    "                    df_trampoline.to_sql(name=hash_val, con=conn, if_exists='replace')\n",
    "\n",
    "                # creates temporary df\n",
    "                name = test[\"Name\"].iloc[0].split()\n",
    "                name = name[0].capitalize() + \" \" + name[1].capitalize()\n",
    "                check_df = df_main[(df_main['Name']==name)]\n",
    "                if len(check_df) == 0:\n",
    "                    routine = '1st' \n",
    "                elif len(check_df) == 1:\n",
    "                    routine = '2nd'\n",
    "                elif len(check_df) == 2:\n",
    "                    routine = '1st'\n",
    "                d = {\n",
    "                    'Start Number': start_number, \n",
    "                    \"Gender\": test[\"Gender\"].iloc[0], \n",
    "                    \"Country\": test[\"Country\"].iloc[0], \n",
    "                    \"Phase\": phase, \n",
    "                    \"Routine\": routine, \n",
    "                    \"Name\": name, \n",
    "                    \"Hash\": hash_val\n",
    "                }\n",
    "                df_temp = pd.DataFrame(d, index=[gmc])\n",
    "                df_main = pd.concat([df_main, df_temp])\n",
    "                gmc += 1\n",
    "\n",
    "\n",
    "df_main[\"Phase\"] = 'Final'\n",
    "\n",
    "\n",
    "df_overall = pd.concat([df_overall, df_main])\n",
    "df_overall[\"Gender\"] = 'Men'\n",
    "with engine.connect() as conn:\n",
    "    df_overall.to_sql(name=db_name, con=conn, if_exists='replace')\n",
    "print('Multi Match: {0}, No Match: {1}, All: {2}, Matched: {3}'.format(mmc, nmc, allc, gmc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Women \n",
    "### Qualification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = \"/Users/falkowork/Downloads/Data/WCH Tokyo TRA Damen/Day 1 TRA Women/\"\n",
    "# dataFolder = \"/Users/falkowork/Downloads/Olympia 2021 Tokyo/SOLG_Tokyo_2020_GT_Men_EuroTrampMachines_Logs/\"\n",
    "db_name = \"2019_world_championships_women\"\n",
    "sortedList = sorted(os.listdir(dataFolder))\n",
    "header = ('Start Number', \"Gender\", \"Country\", \"Phase\", \"Routine\", \"Name\", \"Hash\")\n",
    "df_main = pd.DataFrame(columns=header)\n",
    "df_wctokyo = df[(df['Event']=='World Championships') & (df['Location']=='Tokyo') & (df['Gender']=='Women')]\n",
    "df_overall = pd.DataFrame(columns=header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stripname(name):\n",
    "#     # print(name)\n",
    "#     name = name.strip().split()\n",
    "#     return name[0].capitalize() + \" \" + name[1].capitalize()\n",
    "#     # print(name)\n",
    "\n",
    "startlist = pd.read_csv(\"WCH_Tokyo_Startlist_Women.csv\", header=None)\n",
    "header = ('Start', 'Start Number', 'Name', 'Country')\n",
    "startlist.columns = header\n",
    "# startlist[\"Name\"] = startlist.apply(lambda x: x[\"Name\"].strip(), axis=1)\n",
    "startlist[\"Name\"] = startlist.apply(lambda x: stripname(x[\"Name\"]), axis=1)\n",
    "group_list = []\n",
    "group = 0\n",
    "last_idx = 0\n",
    "routine = '1st'\n",
    "routine_list = []\n",
    "groups = [1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9]\n",
    "for entry in startlist[\"Start\"]:\n",
    "    \n",
    "    # print(\"Last Index {0} - Entry {1}\".format(last_idx, entry))\n",
    "    if last_idx >= entry:\n",
    "        last_idx = 0\n",
    "        group += 1\n",
    "        if routine == '1st':\n",
    "            routine = '2nd'\n",
    "        elif routine == '2nd':\n",
    "            routine = '1st'\n",
    "    else:\n",
    "        last_idx = entry\n",
    "\n",
    "    group_list.append(groups[group])\n",
    "    routine_list.append(routine)\n",
    "\n",
    "startlist[\"Group\"] = group_list\n",
    "startlist[\"Routine\"] = routine_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat = pd.DataFrame(columns=('Filename', 'T', 'H'))\n",
    "filenames = []\n",
    "t_list = []\n",
    "h_list = []\n",
    "hash_table = []\n",
    "for dataset in sortedList:\n",
    "        if not \".DS_Store\" in dataset:\n",
    "            datContent = [i.strip().split() for i in open(dataFolder + dataset).readlines()]\n",
    "            trampoline_data = datContent[4:14]\n",
    "            df_trampoline = pd.DataFrame(trampoline_data)\n",
    "            if len(df_trampoline.columns) > 2:\n",
    "                df_trampoline.drop([0, 1, 3], axis=1,inplace=True)\n",
    "                header = (\"T\", \"H\", \"x\", \"y\")\n",
    "                df_trampoline.columns = header\n",
    "                sum_h = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['H'].to_list()])\n",
    "                sum_t = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['T'].to_list()])\n",
    "                t_list.append(sum_t)\n",
    "                h_list.append(sum_h)\n",
    "                hash_val = hashlib.md5(dataset.encode('UTF-8')).hexdigest()\n",
    "                hash_table.append(hash_val)\n",
    "                with engine.connect() as conn:\n",
    "                    df_trampoline.to_sql(name=hash_val, con=conn, if_exists='replace')\n",
    "                \n",
    "            else:\n",
    "                t_list.append(0)\n",
    "                h_list.append(0)\n",
    "                hash_table.append('')\n",
    "            filenames.append(dataset)\n",
    "df_dat['Filename'] = filenames\n",
    "df_dat['H'] = h_list\n",
    "df_dat['T'] = t_list\n",
    "df_dat['Hash'] = hash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j8/4ddprkx52x3f2x85fg7w74k00000gn/T/ipykernel_82037/179338384.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_wctokyo[\"Name\"] = df_wctokyo.apply(lambda x: stripname(x[\"Name\"]), axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_datsave = df_dat.copy()\n",
    "h_rating = []\n",
    "t_rating = []\n",
    "dataset_list = []\n",
    "matched = 0\n",
    "hash_list = []\n",
    "df_wctokyo[\"Name\"] = df_wctokyo.apply(lambda x: stripname(x[\"Name\"]), axis=1)\n",
    "for idx, entry in startlist.iterrows():\n",
    "    # print(entry[\"Name\"])\n",
    "    # print(entry[\"Routine\"])\n",
    "    entry_with_rating = df_wctokyo[(df_wctokyo['Name']==entry['Name']) & (df_wctokyo['Routine']==entry['Routine'])]\n",
    "    # print(\"Startlist  Name: \" + entry['Name'])\n",
    "    if len(entry_with_rating) > 0:\n",
    "        # print(\"Ratinglist Name: \"+ entry_with_rating['Name'].iloc[0])\n",
    "        h_rating.append(entry_with_rating['H'].iloc[0])\n",
    "        t_rating.append(entry_with_rating['T'].iloc[0])\n",
    "        # test = df_wctokyo[(round(df_wctokyo['H']*1000).astype(int)==sum_h) & (round(df_wctokyo['T']*1000).astype(int)==sum_t)]\n",
    "\n",
    "        h_cents = int(round(entry_with_rating['H'].iloc[0]*1000))\n",
    "        t_cents = int(round(entry_with_rating['T'].iloc[0]*1000))\n",
    "\n",
    "        df_select = df_datsave[((df_datsave['H']==h_cents) & (df_datsave['T']==t_cents))]\n",
    "        # print(df_select)\n",
    "        # print('H: {0}, T: {1}'.format(h_cents, t_cents))\n",
    "        if len(df_select) > 0:\n",
    "            # print('Match found')\n",
    "            dataset_list.append(df_select['Filename'].iloc[0])\n",
    "            # print(df_select['Hash'])\n",
    "            hash_list.append(df_select['Hash'].iloc[0])\n",
    "            df_datsave = df_datsave.drop([df_select.index[0]])\n",
    "            matched += 1\n",
    "        elif len(df_select) == 0:\n",
    "            # print('H: {0} vs {1}, T: {2} vs {3}'.format(df_datsave['H'], h_cents, df_datsave['T'], t_cents))\n",
    "            dataset_list.append('')\n",
    "            hash_list.append('')\n",
    "    elif len(entry_with_rating) == 0:\n",
    "        # print('Name not found ' + entry['Name'] + 'at Routine: ' + entry['Routine'])\n",
    "        h_rating.append(0)\n",
    "        t_rating.append(0)\n",
    "        dataset_list.append('')\n",
    "        hash_list.append('')\n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "startlist['H'] = h_rating\n",
    "startlist['T'] = t_rating\n",
    "startlist['Filename'] = dataset_list\n",
    "startlist[\"Phase\"] = \"Qualification\"\n",
    "startlist['Hash'] = hash_list\n",
    "startlist = startlist.drop([\"Start\", \"Filename\", \"Group\", 'T', 'H'], axis=1)\n",
    "# startlist.to_sql(name=db_name, con=connection)\n",
    "# connection.close()\n",
    "# print(matched)\n",
    "df_overall = pd.concat([df_overall, startlist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = \"/Users/falkowork/Downloads/Data/WCH Tokyo TRA Damen/Day 3 TRA Women/\"\n",
    "# dataFolder = \"/Users/falkowork/Downloads/Olympia 2021 Tokyo/SOLG_Tokyo_2020_GT_Men_EuroTrampMachines_Logs/\"\n",
    "db_name = \"2019_world_championships_women\"\n",
    "sortedList = sorted(os.listdir(dataFolder))\n",
    "header = ('Start Number', \"Gender\", \"Country\", \"Phase\", \"Routine\", \"Name\", \"Hash\")\n",
    "df_main = pd.DataFrame(columns=header)\n",
    "# connection = sqlite3.connect(\"trampoline.db\")\n",
    "# cursor = connection.cursor()\n",
    "# df = pd.read_sql(\"SELECT * from ranklists\", connection)\n",
    "df_wctokyo = df[(df['Event']=='World Championships') & (df['Location']=='Tokyo') & (df['Gender']=='Women') & (df['Phase']=='Semi')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: 9000, T: 15130\n",
      "H: 9200, T: 15095\n",
      "H: 1600, T: 3285\n",
      "H: 4300, T: 7580\n",
      "H: 9300, T: 15675\n",
      "H: 4500, T: 7985\n",
      "H: 9200, T: 14775\n",
      "H: 9400, T: 15515\n",
      "H: 9500, T: 15190\n",
      "H: 5800, T: 9245\n",
      "H: 9300, T: 15330\n",
      "H: 9100, T: 14750\n",
      "H: 9500, T: 15340\n",
      "H: 8900, T: 15325\n",
      "H: 9200, T: 15380\n",
      "H: 9500, T: 15230\n",
      "H: 9100, T: 15165\n",
      "H: 9300, T: 15665\n",
      "H: 9600, T: 14880\n",
      "H: 9300, T: 15390\n",
      "H: 8200, T: 14330\n",
      "H: 9600, T: 15990\n",
      "H: 9600, T: 16120\n",
      "H: 2800, T: 5065\n",
      "Multi Match: 0, No Match: 1, All: 33, Matched: 23\n"
     ]
    }
   ],
   "source": [
    "routine = '0'\n",
    "phase = '0'\n",
    "t_list = []\n",
    "mmc = 0\n",
    "nmc = 0\n",
    "gmc = 0\n",
    "allc = 0\n",
    "names = []\n",
    "h_list = []\n",
    "t_s = []\n",
    "start_number = 0\n",
    "for dataset in sortedList:\n",
    "    if not \".DS_Store\" in dataset:\n",
    "        allc += 1\n",
    "        # idx += 1\n",
    "        # print(idx)\n",
    "        datContent = [i.strip().split() for i in open(dataFolder + dataset).readlines()]\n",
    "        trampoline_data = datContent[4:14]\n",
    "        df_trampoline = pd.DataFrame(trampoline_data)\n",
    "        which_competition = datContent[0][-1]\n",
    "        if (len(df_trampoline.columns) > 2 and int(which_competition) < 3):\n",
    "            df_trampoline.drop([0, 1, 3], axis=1,inplace=True)\n",
    "            header = (\"T\", \"H\", \"x\", \"y\")\n",
    "            df_trampoline.columns = header\n",
    "            sum_h = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['H'].to_list()])\n",
    "            sum_t = np.sum([int(Decimal(i)*1000) if i != None else 0 for i in df_trampoline['T'].to_list()])\n",
    "            \n",
    "            \n",
    "            test = df_wctokyo[(round(df_wctokyo['H']*1000).astype(int)==sum_h) & (round(df_wctokyo['T']*1000).astype(int)==sum_t)]\n",
    "            # if dataset == '20210731_135110.dat':\n",
    "            print('H: {0}, T: {1}'.format(sum_h, sum_t))\n",
    "            #     print(df_trampoline)\n",
    "            if len(test) > 1:\n",
    "                mmc += 1\n",
    "                # print(dataset)\n",
    "                # print(test['Name'])\n",
    "            elif len(test) == 0:\n",
    "                nmc += 1\n",
    "                # print(dataset)\n",
    "                # print(\"No Match\")\n",
    "                # print(sum_t)\n",
    "            elif len(test) == 1:\n",
    "                # if gmc == 0:\n",
    "                #     print('H: {0}, T: {1}'.format(sum_h, sum_t))\n",
    "                #     print(test)\n",
    "                t_list.append(sum_t)\n",
    "                h_list.append(sum_h)\n",
    "                names.append(test[\"Name\"].iloc[0])\n",
    "\n",
    "                # creates hash from filename\n",
    "                hash_val = hashlib.md5(dataset.encode('UTF-8')).hexdigest()\n",
    "                with engine.connect() as conn:\n",
    "                    df_trampoline.to_sql(name=hash_val, con=conn)\n",
    "\n",
    "                # creates temporary df\n",
    "                name = test[\"Name\"].iloc[0].split()\n",
    "                name = name[0].capitalize() + \" \" + name[1].capitalize()\n",
    "                check_df = df_main[(df_main['Name']==name)]\n",
    "                if len(check_df) == 0:\n",
    "                    routine = '1st'\n",
    "                    phase = 'Qualification'\n",
    "                elif len(check_df) == 1:\n",
    "                    routine = '2nd'\n",
    "                    phase = 'Qualification'\n",
    "                elif len(check_df) == 2:\n",
    "                    routine = '1st'\n",
    "                    phase = 'Final'\n",
    "                d = {\n",
    "                    'Start Number': start_number, \n",
    "                    \"Gender\": test[\"Gender\"].iloc[0], \n",
    "                    \"Country\": test[\"Country\"].iloc[0], \n",
    "                    \"Phase\": phase, \n",
    "                    \"Routine\": routine, \n",
    "                    \"Name\": name, \n",
    "                    \"Hash\": hash_val\n",
    "                }\n",
    "                df_temp = pd.DataFrame(d, index=[gmc])\n",
    "                df_main = pd.concat([df_main, df_temp])\n",
    "                gmc += 1\n",
    "\n",
    "df_main[\"Phase\"] = 'Semi'\n",
    "# df_main.to_sql(name=db_name, con=connection)\n",
    "# connection.close()\n",
    "df_overall = pd.concat([df_overall, df_main])\n",
    "print('Multi Match: {0}, No Match: {1}, All: {2}, Matched: {3}'.format(mmc, nmc, allc, gmc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = \"/Users/falkowork/Downloads/Data/WCH Tokyo TRA Damen/Day 4 TRA Women/\"\n",
    "# dataFolder = \"/Users/falkowork/Downloads/Olympia 2021 Tokyo/SOLG_Tokyo_2020_GT_Men_EuroTrampMachines_Logs/\"\n",
    "db_name = \"2019_world_championships_women\"\n",
    "sortedList = sorted(os.listdir(dataFolder))\n",
    "header = ('Start Number', \"Gender\", \"Country\", \"Phase\", \"Routine\", \"Name\", \"Hash\")\n",
    "df_main = pd.DataFrame(columns=header)\n",
    "# connection = sqlite3.connect(\"trampoline.db\")\n",
    "# cursor = connection.cursor()\n",
    "# df = pd.read_sql(\"SELECT * from ranklists\", connection)\n",
    "df_wctokyo = df[(df['Event']=='World Championships') & (df['Location']=='Tokyo') & (df['Gender']=='Women') & (df['Phase']=='Final')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: 8900, T: 14850\n",
      "H: 1000, T: 1685\n",
      "H: 9600, T: 15525\n",
      "H: 8800, T: 15320\n",
      "H: 9500, T: 15220\n",
      "H: 9200, T: 15290\n",
      "H: 9500, T: 15860\n",
      "H: 8900, T: 15905\n",
      "H: 9300, T: 14860\n",
      "H: 9500, T: 15120\n",
      "H: 9000, T: 15965\n",
      "H: 9600, T: 15200\n",
      "H: 9200, T: 15530\n",
      "Multi Match: 0, No Match: 5, All: 17, Matched: 8\n"
     ]
    }
   ],
   "source": [
    "routine = '0'\n",
    "phase = '0'\n",
    "t_list = []\n",
    "mmc = 0\n",
    "nmc = 0\n",
    "gmc = 0\n",
    "allc = 0\n",
    "names = []\n",
    "h_list = []\n",
    "t_s = []\n",
    "start_number = 0\n",
    "for dataset in sortedList:\n",
    "    if not \".DS_Store\" in dataset:\n",
    "        allc += 1\n",
    "        # idx += 1\n",
    "        # print(idx)\n",
    "        datContent = [i.strip().split() for i in open(dataFolder + dataset).readlines()]\n",
    "        trampoline_data = datContent[4:14]\n",
    "        df_trampoline = pd.DataFrame(trampoline_data)\n",
    "        which_competition = datContent[0][-1]\n",
    "        if (len(df_trampoline.columns) > 2 and int(which_competition) < 3):\n",
    "            df_trampoline.drop([0, 1, 3], axis=1,inplace=True)\n",
    "            header = (\"T\", \"H\", \"x\", \"y\")\n",
    "            df_trampoline.columns = header\n",
    "            sum_h = np.sum([int(Decimal(i)*1000) if i is not None else 0 for i in df_trampoline['H'].to_list()])\n",
    "            sum_t = np.sum([int(Decimal(i)*1000) if i is not None else 0 for i in df_trampoline['T'].to_list()])\n",
    "            \n",
    "            \n",
    "            test = df_wctokyo[(round(df_wctokyo['H']*1000).astype(int)==sum_h) & (round(df_wctokyo['T']*1000).astype(int)==sum_t)]\n",
    "            # if dataset == '20210731_135110.dat':\n",
    "            print('H: {0}, T: {1}'.format(sum_h, sum_t))\n",
    "            #     print(df_trampoline)\n",
    "            if len(test) > 1:\n",
    "                mmc += 1\n",
    "                # print(dataset)\n",
    "                # print(test['Name'])\n",
    "            elif len(test) == 0:\n",
    "                nmc += 1\n",
    "                # print(dataset)\n",
    "                # print(\"No Match\")\n",
    "                # print(sum_t)\n",
    "            elif len(test) == 1:\n",
    "                # if gmc == 0:\n",
    "                #     print('H: {0}, T: {1}'.format(sum_h, sum_t))\n",
    "                #     print(test)\n",
    "                t_list.append(sum_t)\n",
    "                h_list.append(sum_h)\n",
    "                names.append(test[\"Name\"].iloc[0])\n",
    "\n",
    "                # creates hash from filename\n",
    "                hash_val = hashlib.md5(dataset.encode('UTF-8')).hexdigest()\n",
    "                with engine.connect() as conn:\n",
    "                    df_trampoline.to_sql(name=hash_val, con=conn, if_exists='replace')\n",
    "\n",
    "                # creates temporary df\n",
    "                name = test[\"Name\"].iloc[0].split()\n",
    "                name = name[0].capitalize() + \" \" + name[1].capitalize()\n",
    "                check_df = df_main[(df_main['Name']==name)]\n",
    "                if len(check_df) == 0:\n",
    "                    routine = '1st' \n",
    "                elif len(check_df) == 1:\n",
    "                    routine = '2nd'\n",
    "                elif len(check_df) == 2:\n",
    "                    routine = '1st'\n",
    "                d = {\n",
    "                    'Start Number': start_number, \n",
    "                    \"Gender\": test[\"Gender\"].iloc[0], \n",
    "                    \"Country\": test[\"Country\"].iloc[0], \n",
    "                    \"Phase\": phase, \n",
    "                    \"Routine\": routine, \n",
    "                    \"Name\": name, \n",
    "                    \"Hash\": hash_val\n",
    "                }\n",
    "                df_temp = pd.DataFrame(d, index=[gmc])\n",
    "                df_main = pd.concat([df_main, df_temp])\n",
    "                gmc += 1\n",
    "\n",
    "\n",
    "df_main[\"Phase\"] = 'Final'\n",
    "\n",
    "# connection.close()\n",
    "df_overall = pd.concat([df_overall, df_main])\n",
    "df_overall[\"Gender\"] = 'Women'\n",
    "with engine.connect() as conn:\n",
    "    df_overall.to_sql(name=db_name, con=conn, if_exists='replace')\n",
    "print('Multi Match: {0}, No Match: {1}, All: {2}, Matched: {3}'.format(mmc, nmc, allc, gmc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sql')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3074d61cef3f9d3d76d48957e026783c1a4ff696d0fad7cb10fc19cd667d8c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
